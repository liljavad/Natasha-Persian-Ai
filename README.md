<div align="center">

# Project Natasha ğŸ¤–
### A Novel Framework for Persian Conversational AI
<p>
  <img src="https://img.shields.io/badge/Language-Python-3776AB?style=for-the-badge&logo=python" alt="Language: Python">
  <img src="https://img.shields.io/badge/Library-Hugging_Face-FFD000?style=for-the-badge&logo=huggingface" alt="Library: Hugging Face">
  <img src="https://img.shields.io/badge/Framework-Flask-000000?style=for-the-badge&logo=flask" alt="Framework: Flask">
  <img src="https://img.shields.io/badge/Status-In_Development-purple?style=for-the-badge" alt="Status: In Development">
  <img src="https://img.shields.io/badge/License-Proprietary-red?style=for-the-badge" alt="License: Proprietary">
</p>

**[English](#english) | [ÙØ§Ø±Ø³ÛŒ (Persian)](#persian-farsi)**

</div>

---

<p align="center">
    <img src="https://imgur.com/Qbj70Wt.png" alt="Natasha UI Demo" style="width:100%; max-width:700px; border-radius:15px; border: 1px solid #333;"/>
</p>

---

## <a name="english"></a>ğŸ‡¬ğŸ‡§ English

### Abstract

Project Natasha is a research and development initiative focused on creating a high-efficacy conversational AI specifically for the **Persian language**. Addressing the challenges of data scarcity and the morpho-syntactic complexity of Persian, this project introduces a novel pipeline centered around a **Conceptual Tokenizer**. This method creates a semantic abstraction layer by performing unsupervised clustering on word embeddings, allowing a foundational model to learn deeper contextual patterns from a limited dataset. A pre-trained T5-based transformer model was fine-tuned on this conceptual representation, resulting in a lightweight, efficient, and contextually aware chatbot.

### Core Methodology

The Natasha framework is built upon a unique multi-stage pipeline that differentiates it from standard fine-tuning approaches.

#### ğŸ§  The Concept Engine
The cornerstone of this project is a proprietary data processing pipeline we term the "Concept Engine." Instead of processing raw lexical units, the engine maps them to a condensed semantic space.

1.  **Embedding Generation:** A pre-trained multilingual model (`Sentence-Transformers`) is used to generate high-dimensional semantic vectors for each unique token.
2.  **Unsupervised Clustering:** The K-Means algorithm groups semantically similar tokens into a predefined number of clusters, where each cluster represents a distinct "concept."
3.  **Corpus Transformation:** The entire training dataset is then transformed by replacing each token with its corresponding Concept ID (e.g., `C56`).

This transformation results in a dataset where the model learns relationships between abstract ideas rather than literal words, leading to more robust pattern recognition and superior data efficiency.

#### âš™ï¸ Model Architecture and Fine-Tuning
We employed a **Transfer Learning** strategy using the `t5-small` model as our foundation. This powerful and efficient Text-to-Text Transformer was then fine-tuned on the conceptually transformed Persian conversational dataset.

### ğŸ”¬ A Glimpse into the "Concept Engine"
This is the core logic that translates words into abstract concepts. Instead of seeing individual words, the model learns from the underlying ideas, making it incredibly data-efficient.
<details>
<summary>Click to see a Python code snippet</summary>

```python
# Load the unique vocabulary from the preprocessed data
words = list(vocab_data.keys())
print(f"Embedding {len(words)} unique tokens...")

# Use a powerful multilingual model to generate semantic vectors
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
word_embeddings = model.encode(words, show_progress_bar=True)

print("Clustering vectors into semantic concepts using KMeans...")
# Group similar word vectors into N distinct concepts
kmeans = KMeans(n_clusters=NUM_CONCEPTS, random_state=42, n_init=10)
kmeans.fit(word_embeddings)

# Create the final map from a word to its abstract Concept ID
word_to_concept = {word: int(cluster_id) for word, cluster_id in zip(words, kmeans.labels_)}

print("âœ… Conceptual map created successfully!")
```
</details>

### ğŸ› ï¸ Technology Stack

| Category      | Technologies                                                                                  |
|---------------|-----------------------------------------------------------------------------------------------|
| **AI/ML** | `Python`, `Hugging Face Transformers`, `PyTorch`, `Sentence-Transformers`, `Scikit-learn`         |
| **Backend** | `Flask`, `Gunicorn`                                                                           |
| **Frontend** | `HTML5`, `CSS3` (with animations & glassmorphism), `JavaScript` (Live streaming & dynamic UI) |
| **Persian NLP** | `Hazm`                                                                                        |

### ğŸ—ºï¸ Project Roadmap

Project Natasha is currently under active development with a focus on research, refinement, and performance optimization.

-   **[âœ…] Phase 1:** Development of the Concept Engine - *Completed*
-   **[âœ…] Phase 2:** Training of the initial prototype model - *Completed*
-   **[âœ…] Phase 3:** Development of the advanced, dynamic web interface - *Completed*
-   **[ğŸš€] Phase 4:** Model optimization and preparation for demonstration - *In Progress*

#### Public Release Outlook (Q1 2026)
Our goal is to release the first interactive **Public Demo** of Project Natasha in the first quarter of 2026. This demo will allow users to experience the capabilities of our conceptually-driven model firsthand. Further announcements regarding potential API access for research or commercial purposes will follow the demo release.

### ğŸ’¬ Community & Communication

This is a proprietary project, but community feedback and questions are highly valued. The best way to communicate with us is right here on GitHub.

-   **Have a question or a new idea?** ğŸ‘‰ [**Start a new Discussion**](https://github.com/liljavad/Natasha-Persian-Ai.git/discussions)
-   **Found a bug or have a feature request?** ğŸ‘‰ [**Open an Issue**](https://github.com/liljavad/Natasha-Persian-Ai.git/issues)
-   **Want to stay updated?** ğŸ‘‰ **Star (â­)** and **Watch (ğŸ‘ï¸)** this repository!

We actively monitor these channels and look forward to hearing from the community.

---
---

## <a name="persian-farsi"></a>ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ (Persian)

### Ú†Ú©ÛŒØ¯Ù‡

Ù¾Ø±ÙˆÚ˜Ù‡ Ù†Ø§ØªØ§Ø´Ø§ ÛŒÚ© Ø·Ø±Ø­ ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø± Ø³Ø§Ø®Øª ÛŒÚ© Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø§Ù„Ø§ØŒ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ **Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ**ØŒ ØªÙ…Ø±Ú©Ø² Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù…Ø¨ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ùˆ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒØŒ ÛŒÚ© Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† Ù†ÙˆØ¢ÙˆØ±Ø§Ù†Ù‡ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± **Â«ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± Ù…ÙÙ‡ÙˆÙ…ÛŒÂ»** Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø±ÙˆÛŒ Ø¨Ø§Ø²Ù†Ù…Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ú©Ù„Ù…Ø§ØªØŒ ÛŒÚ© Ù„Ø§ÛŒÙ‡ Ø§Ù†ØªØ²Ø§Ø¹ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±ÛŒ Ø±Ø§ Ø§Ø² ÛŒÚ© Ø¯ÛŒØªØ§Ø³Øª Ù…Ø­Ø¯ÙˆØ¯ Ø¨ÛŒØ§Ù…ÙˆØ²Ø¯. ÛŒÚ© Ù…Ø¯Ù„ ØªØ±Ù†Ø³ÙÙˆØ±Ù…Ø± Ø§Ø² Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± T5 Ø¨Ø± Ø±ÙˆÛŒ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ (Fine-tune) Ø´Ø¯Ù‡ Ú©Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¢Ù†ØŒ ÛŒÚ© Ú†Øªâ€ŒØ¨Ø§Øª Ø³Ø¨Ú©ØŒ Ú©Ø§Ø±Ø¢Ù…Ø¯ Ùˆ Ø¢Ú¯Ø§Ù‡ Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ú¯ÙØªÚ¯Ùˆ Ø§Ø³Øª.

### Ù…ØªØ¯ÙˆÙ„ÙˆÚ˜ÛŒ Ø§ØµÙ„ÛŒ

Ú†Ø§Ø±Ú†ÙˆØ¨ Ù†Ø§ØªØ§Ø´Ø§ Ø¨Ø± ÛŒÚ© Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ø¨Ù†Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø¢Ù† Ø±Ø§ Ø§Ø² Ø±ÙˆÛŒÚ©Ø±Ø¯Ù‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…ØªÙ…Ø§ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

#### ğŸ§  Ù…ÙˆØªÙˆØ± Ù…ÙÙ‡ÙˆÙ…ÛŒ (Concept Engine)
Ø³Ù†Ú¯ Ø¨Ù†Ø§ÛŒ Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ØŒ Ù¾Ø§ÛŒÙ¾â€ŒÙ„Ø§ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ø§Ø®ØªØµØ§ØµÛŒ Ù…Ø§Ø³Øª Ú©Ù‡ Ø¢Ù† Ø±Ø§ Â«Ù…ÙˆØªÙˆØ± Ù…ÙÙ‡ÙˆÙ…ÛŒÂ» Ù…ÛŒâ€ŒÙ†Ø§Ù…ÛŒÙ…. Ø§ÛŒÙ† Ù…ÙˆØªÙˆØ± Ø¨Ù‡ Ø¬Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù„Ù…Ø§Øª Ø®Ø§Ù…ØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÛŒÚ© ÙØ¶Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ ÙØ´Ø±Ø¯Ù‡ Ù†Ú¯Ø§Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

1.  **ØªÙˆÙ„ÛŒØ¯ Ø¨Ø§Ø²Ù†Ù…Ø§ÛŒÛŒ Ø¨Ø±Ø¯Ø§Ø±ÛŒ:** ÛŒÚ© Ù…Ø¯Ù„ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ (`Sentence-Transformers`) Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÚ©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ ÛŒÚ©ØªØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
2.  **Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø§Ø±Øª:** Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… K-Means ÙˆÚ©ØªÙˆØ±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ø§ØªÙ Ø¨Ø§ Ù…Ø¹Ù†Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø±Ø§ Ø¯Ø± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù‡Ø± Ø®ÙˆØ´Ù‡ Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡ ÛŒÚ© Â«Ù…ÙÙ‡ÙˆÙ…Â» Ù…Ø¬Ø²Ø§Ø³Øª.
3.  **ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒØªØ§Ø³Øª:** Ú©Ù„ Ø¯ÛŒØªØ§Ø³Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ù…ØªÙ†Ø§Ø¸Ø± Ø¢Ù† (Ù…Ø«Ù„Ø§Ù‹ `C56`) Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

Ø§ÛŒÙ† ØªØ­ÙˆÙ„ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ù‡ Ø¬Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ú©Ù„Ù…Ø§ØªØŒ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ²Ø§Ø¹ÛŒ Ø±Ø§ Ø¨ÛŒØ§Ù…ÙˆØ²Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÛŒ Ù‚ÙˆÛŒâ€ŒØªØ± Ùˆ Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ù…Ù†Ø¬Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯.

#### âš™ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„
Ù…Ø§ Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ **ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ (Transfer Learning)** Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ `t5-small` Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø§ÛŒÙ‡ Ø¨Ù‡Ø±Ù‡ Ø¨Ø±Ø¯ÛŒÙ…. Ø§ÛŒÙ† ØªØ±Ù†Ø³ÙÙˆØ±Ù…Ø± Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ø³Ù¾Ø³ Ø¨Ø± Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª Ù…ÙÙ‡ÙˆÙ…ÛŒâ€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ ÙØ§Ø±Ø³ÛŒØŒ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ø´Ø¯.


### ğŸ”¬ Ù†Ú¯Ø§Ù‡ÛŒ Ø¨Ù‡ Ú©Ø¯ Â«Ù…ÙˆØªÙˆØ± Ù…ÙÙ‡ÙˆÙ…ÛŒÂ»
Ø§ÛŒÙ† Ø¨Ø®Ø´ØŒ Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù„Ù…Ø§Øª Ø¨Ù‡ Ù…ÙØ§Ù‡ÛŒÙ… Ø§Ù†ØªØ²Ø§Ø¹ÛŒ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ù…Ø¯Ù„ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ú©Ù„Ù…Ø§Øª Ù…Ø¬Ø²Ø§ØŒ Ø§Ø² Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒÙ† Ø¢Ù†â€ŒÙ‡Ø§ ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ú©Ù‡ Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø±Ø§ Ø¨Ù‡ Ø·Ø±Ø² Ø´Ú¯ÙØªâ€ŒØ§Ù†Ú¯ÛŒØ²ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
<details>
<summary>Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ú©Ø¯ Ù¾Ø§ÛŒØªÙˆÙ† Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</summary>

```python
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ§Ú˜Ú¯Ø§Ù† ÛŒÚ©ØªØ§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
words = list(vocab_data.keys())
print(f"Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ {len(words)} ØªÙˆÚ©Ù† ÛŒÚ©ØªØ§...")

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÚ©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
word_embeddings = model.encode(words, show_progress_bar=True)

print("Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÚ©ØªÙˆØ±Ù‡Ø§ Ø¨Ù‡ Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø§ KMeans...")
# Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÚ©ØªÙˆØ±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø± N Ù…ÙÙ‡ÙˆÙ… Ù…Ø¬Ø²Ø§
kmeans = KMeans(n_clusters=NUM_CONCEPTS, random_state=42, n_init=10)
kmeans.fit(word_embeddings)

# Ø³Ø§Ø®Øª Ù†Ù‚Ø´Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø² Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¨Ù‡ Ø´Ù†Ø§Ø³Ù‡ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø§Ù†ØªØ²Ø§Ø¹ÛŒ Ø¢Ù†
word_to_concept = {word: int(cluster_id) for word, cluster_id in zip(words, kmeans.labels_)}

print("âœ… Ù†Ù‚Ø´Ù‡ Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯!")
```
</details>

### ğŸ› ï¸ Ù¾Ø´ØªÙ‡ ÙÙ†Ø§ÙˆØ±ÛŒ (Technology Stack)

| Ø¯Ø³ØªÙ‡          | ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§                                                                                    |
|---------------|-----------------------------------------------------------------------------------------------|
| **Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ**| `Python`, `Hugging Face Transformers`, `PyTorch`, `Sentence-Transformers`, `Scikit-learn`         |
| **Ø¨Ú©â€ŒØ§Ù†Ø¯** | `Flask`, `Gunicorn`                                                                           |
| **ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯** | `HTML5`, `CSS3` (Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ùˆ Ú¯Ù„Ø³â€ŒÙ…ÙˆØ±ÙÛŒØ³Ù…), `JavaScript` (ØªØ§ÛŒÙ¾ Ø²Ù†Ø¯Ù‡ Ùˆ UI Ù¾ÙˆÛŒØ§) |
| **Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ**| `Hazm`                                                                                        |

### ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡

Ù¾Ø±ÙˆÚ˜Ù‡ Ù†Ø§ØªØ§Ø´Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± ÙØ§Ø² ØªÙˆØ³Ø¹Ù‡ ÙØ¹Ø§Ù„ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± ØªØ­Ù‚ÛŒÙ‚ØŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªØ¯ÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.

-   **[âœ…] ÙØ§Ø² Û±:** ØªÙˆØ³Ø¹Ù‡ Ù…ÙˆØªÙˆØ± Ù…ÙÙ‡ÙˆÙ…ÛŒ - *Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØªÙ‡*
-   **[âœ…] ÙØ§Ø² Û²:** Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø§ÙˆÙ„ÛŒÙ‡ - *Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØªÙ‡*
-   **[âœ…] ÙØ§Ø² Û³:** Ø·Ø±Ø§Ø­ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ Ù¾ÙˆÛŒØ§ - *Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØªÙ‡*
-   **[ğŸš€] ÙØ§Ø² Û´:** Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù…Ùˆ - *Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…*

#### Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø² Ø§Ù†ØªØ´Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ (Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡ Ø§ÙˆÙ„ Û²Û°Û²Û¶)
Ù‡Ø¯Ù Ù…Ø§ Ø§Ù†ØªØ´Ø§Ø± Ø§ÙˆÙ„ÛŒÙ† **Ø¯Ù…ÙˆÛŒ Ø¹Ù…ÙˆÙ…ÛŒ** Ùˆ ØªØ¹Ø§Ù…Ù„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ù†Ø§ØªØ§Ø´Ø§ Ø¯Ø± Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡ Ø§ÙˆÙ„ Ø³Ø§Ù„ Û²Û°Û²Û¶ Ø§Ø³Øª. Ø§ÛŒÙ† Ø¯Ù…Ùˆ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ Ù…ÙÙ‡ÙˆÙ…â€ŒÙ…Ø­ÙˆØ± Ù…Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ú©Ù†Ù†Ø¯. Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ù‡ API Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ ÛŒØ§ ØªØ¬Ø§Ø±ÛŒØŒ Ù¾Ø³ Ø§Ø² Ø§Ù†ØªØ´Ø§Ø± Ø¯Ù…Ùˆ Ø§Ø¹Ù„Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.

### ğŸ’¬ Ø§Ø±ØªØ¨Ø§Ø· Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ

Ø§ÛŒÙ† ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ù†Ø­ØµØ§Ø±ÛŒ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ùˆ Ø³ÙˆØ§Ù„Ø§Øª Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø§Ø±Ø²Ø´ Ø²ÛŒØ§Ø¯ÛŒ Ù‚Ø§Ø¦Ù„ Ù‡Ø³ØªÛŒÙ…. Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø§ØŒ Ù‡Ù…ÛŒÙ†â€ŒØ¬Ø§ Ø¯Ø± Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ Ø§Ø³Øª.

-   **Ø³ÙˆØ§Ù„ ÛŒØ§ Ø§ÛŒØ¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŸ** ğŸ‘ˆ [**ÛŒÚ© Ú¯ÙØªÚ¯ÙˆÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø¨Ø®Ø´ Discussions Ø¢ØºØ§Ø² Ú©Ù†ÛŒØ¯**](https://github.com/liljavad/Natasha-Persian-Ai.git/discussions)
-   **Ø¨Ø§Ú¯ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯ÛŒØ¯ ÛŒØ§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù‚Ø§Ø¨Ù„ÛŒØªÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŸ** ğŸ‘ˆ [**ÛŒÚ© Ø§ÛŒØ´Ùˆ (Issue) Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ø² Ú©Ù†ÛŒØ¯**](https://github.com/liljavad/Natasha-Persian-Ai/issues)
-   **Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ù…Ø·Ù„Ø¹ Ø´ÙˆÛŒØ¯ØŸ** ğŸ‘ˆ Ø§ÛŒÙ† Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ Ø±Ø§ **Ø§Ø³ØªØ§Ø± (â­)** Ùˆ **ÙˆØ§Ú† (ğŸ‘ï¸)** Ú©Ù†ÛŒØ¯!

Ù…Ø§ Ø§ÛŒÙ† Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± ÙØ¹Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ùˆ Ù…Ø´ØªØ§Ù‚Ø§Ù†Ù‡ Ù…Ù†ØªØ¸Ø± Ø´Ù†ÛŒØ¯Ù† Ù†Ø¸Ø±Ø§Øª Ø´Ù…Ø§ Ù‡Ø³ØªÛŒÙ….
